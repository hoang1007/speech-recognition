{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from typing import Tuple, Iterable, Optional\n",
    "import re\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define The Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "FINETUNE_LR = 1e-5\n",
    "LR = 1e-4\n",
    "EPOCHS = 30\n",
    "TOTAL_STEPS = (42_000 // BATCH_SIZE) * EPOCHS\n",
    "WARMUP_STEPS = int(TOTAL_STEPS * 0.1)\n",
    "CONSTANT_STEPS = int(TOTAL_STEPS * 0.4)\n",
    "WEIGHT_DECAY = 5e-3\n",
    "\n",
    "CKPT_DIR = \"ckpt\"\n",
    "LOG_DIR = \"logs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert original dataset to WebDataset tar file for faster loading on Google Colab\n",
    "from src.datamodule import VLSP2020Dataset, VLSP2020TarDataset\n",
    "\n",
    "# from torch.utils.data import random_split\n",
    "\n",
    "# dts = VLSP2020Dataset(\"../data/vlsp2020_train_set_02\")\n",
    "# train_set, val_set = random_split(dts, [42_000, 14_427])\n",
    "\n",
    "# VLSP2020TarDataset(\"../data/vlsp2020_train_set.tar\").convert(train_set)\n",
    "# VLSP2020TarDataset(\"../data/vlsp2020_val_set.tar\").convert(val_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloader and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VLSP2020TarDataset(\"../data/vlsp2020_train_set.tar\").load()\n",
    "val_dataset = VLSP2020TarDataset(\"../data/vlsp2020_val_set.tar\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from src.datamodule.vlsp2020 import get_dataloader\n",
    "\n",
    "\n",
    "def remove_punctuation(text: str):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    train_dataset,\n",
    "    return_transcript=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_transform=remove_punctuation,\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    val_dataset,\n",
    "    return_transcript=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_transform=remove_punctuation,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('và hình như tôi cảm giác là qua từng vòng thi thì cái họng của bạn tốt hơn rồi thì phải', 'đến đây thì mọi bắt đầu thấy được cuộc chiến khốc liệt như thế nào rồi đúng không ạ họ rất là tính tay rất kĩ thưa quý vị chọn ô màu của mình mời em đọc câu tiếp theo'), (tensor([-0.0012,  0.0088,  0.0054,  ..., -0.0038, -0.0009,  0.0046]), tensor([-0.0760, -0.0811, -0.0728,  ..., -0.0032, -0.0034, -0.0035])))\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(source: Tuple[str], target: Tuple[str]):\n",
    "    \"\"\"\n",
    "    Compute the Levenshtein distance between two sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    n, m = len(source), len(target)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        source, target = target, source\n",
    "        n, m = m, n\n",
    "\n",
    "    current_row = range(n + 1)  # Keep current and previous row, not entire matrix\n",
    "    for i in range(1, m + 1):\n",
    "        previous_row, current_row = current_row, [i] + [0] * n\n",
    "        for j in range(1, n + 1):\n",
    "            add, delete, change = (\n",
    "                previous_row[j] + 1,\n",
    "                current_row[j - 1] + 1,\n",
    "                previous_row[j - 1],\n",
    "            )\n",
    "            if source[j - 1] != target[i - 1]:\n",
    "                change += 1\n",
    "            current_row[j] = min(add, delete, change)\n",
    "\n",
    "    distance = current_row[n]\n",
    "\n",
    "    del current_row\n",
    "    del previous_row\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def word_error_rate(prediction: str, transcript: str):\n",
    "    pattern = r\"\\W+\"\n",
    "\n",
    "    prediction = re.split(pattern, prediction)\n",
    "    transcript = re.split(pattern, transcript)\n",
    "\n",
    "    return levenshtein_distance(prediction, transcript) / len(transcript)\n",
    "\n",
    "\n",
    "def character_error_rate(prediction: str, transcript: str):\n",
    "    return levenshtein_distance(prediction, transcript) / len(transcript)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class VocabBuilder:\n",
    "    DELIM_TOKEN = \"|\"\n",
    "    UNK_TOKEN = \"<unk>\"\n",
    "    PAD_TOKEN = \"<pad>\"\n",
    "\n",
    "    def __init__(self, vocab_file: str):\n",
    "        self.vocab_file = vocab_file\n",
    "        self._vocab_set = set()\n",
    "\n",
    "    def add(self, texts: Iterable[str]):\n",
    "        for t in texts:\n",
    "            self._vocab_set.update(t)\n",
    "\n",
    "    def build(self):\n",
    "        self._vocab_dict = {c: i for i, c in enumerate(self._vocab_set)}\n",
    "\n",
    "        # replace space with pipe for clearer visualization\n",
    "        self._vocab_dict[self.DELIM_TOKEN] = self._vocab_dict[\" \"]\n",
    "        del self._vocab_dict[\" \"]\n",
    "\n",
    "        # add unknown token so that model can handle unseen characters\n",
    "        self._vocab_dict[self.UNK_TOKEN] = len(self._vocab_dict)\n",
    "\n",
    "        # add padding token for CTC\n",
    "        self._vocab_dict[self.PAD_TOKEN] = len(self._vocab_dict)\n",
    "\n",
    "        return self._vocab_dict\n",
    "\n",
    "    @property\n",
    "    def vocab_dict(self):\n",
    "        return self._vocab_dict\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.vocab_file, \"w\") as f:\n",
    "            json.dump(self.vocab_dict, f, ensure_ascii=False)\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.vocab_file, \"r\") as f:\n",
    "            self._vocab_dict = json.load(f)\n",
    "\n",
    "        return self._vocab_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from transformers import (\n",
    "    Wav2Vec2ForPreTraining,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    ")\n",
    "from torchmetrics import MeanMetric\n",
    "\n",
    "from src.utils.scheduler import TriStateScheduler\n",
    "\n",
    "class SpeechRecognizer(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wav2vec2: Wav2Vec2ForPreTraining,\n",
    "        tokenizer: Wav2Vec2CTCTokenizer,\n",
    "        feature_extractor: Wav2Vec2FeatureExtractor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.hidden_size = wav2vec2.config.hidden_size\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "        self.wav2vec2 = wav2vec2\n",
    "        self.wav2vec2.freeze_feature_extractor()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(self.hidden_size // 2, self.vocab_size),\n",
    "        )\n",
    "\n",
    "        self.criterion = torch.nn.CTCLoss(blank=tokenizer.pad_token_id)\n",
    "\n",
    "        self.train_loss = MeanMetric()\n",
    "\n",
    "    def forward(self, waveforms: Tuple[torch.Tensor], transcripts: Tuple[str] = None):\n",
    "        # convert torch.Tensor to numpy.ndarray\n",
    "        waveforms = tuple(waveform.cpu().numpy() for waveform in waveforms)\n",
    "\n",
    "        extracted = self.feature_extractor(\n",
    "            waveforms,\n",
    "            sampling_rate=16000,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        outputs = self.wav2vec2(\n",
    "            extracted.input_values,\n",
    "            attention_mask=extracted.attention_mask,\n",
    "        )\n",
    "\n",
    "        # hidden_states.shape == (batch_size, sequence_length, hidden_size)\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # logits.shape == (batch_size, sequence_length, vocab_size)\n",
    "        logits = self.fc(hidden_states)\n",
    "\n",
    "        if transcripts is not None:\n",
    "            # get the length of valids sequence\n",
    "            input_lengths = self.wav2vec2._get_feat_extract_output_lengths(\n",
    "                extracted.attention_mask.sum(-1)\n",
    "            ).to(torch.long)\n",
    "\n",
    "            # tokenize transcripts\n",
    "            target_ids, target_lengths = self.tokenizer(\n",
    "                transcripts, padding=True, return_length=True, return_tensors=\"pt\"\n",
    "            ).values()\n",
    "\n",
    "            # (batch_size, sequence_length, vocab_size) -> (sequence_length, batch_size, vocab_size)\n",
    "            log_probs = torch.nn.functional.log_softmax(logits, dim=-1).transpose_(0, 1)\n",
    "\n",
    "            # compute loss\n",
    "            loss = self.criterion(log_probs, target_ids, input_lengths, target_lengths)\n",
    "\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        transcripts, waveforms = batch\n",
    "\n",
    "        loss, logits = self(waveforms, transcripts)\n",
    "\n",
    "        self.train_loss(loss)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            self.log(\"train/loss\", self.train_loss, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.train_loss.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        transcripts, waveforms = batch\n",
    "\n",
    "        logits = self(waveforms)\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        predicted_texts = self.tokenizer.batch_decode(predicted_ids)\n",
    "\n",
    "        wer = word_error_rate(predicted_texts, transcripts)\n",
    "        cer = character_error_rate(predicted_texts, transcripts)\n",
    "\n",
    "        self.log(\"val/wer\", wer, on_epoch=True)\n",
    "        self.log(\"val/cer\", cer, on_epoch=True)\n",
    "\n",
    "        return wer, cer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\"params\": self.wav2vec2.parameters(), \"lr\": FINETUNE_LR},\n",
    "            {\"params\": self.fc.parameters(), \"lr\": LR},\n",
    "        ], lr=LR, weight_decay=WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        scheduler = TriStateScheduler(\n",
    "            optimizer,\n",
    "            total_steps=TOTAL_STEPS,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            constant_steps=CONSTANT_STEPS,\n",
    "            factor=1e-3\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h were not used when initializing Wav2Vec2ForPreTraining: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForPreTraining were not initialized from the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h and are newly initialized: ['project_q.bias', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.bias', 'project_hid.weight', 'project_q.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nguyenvulebinh/wav2vec2-base-vietnamese-250h\"\n",
    "\n",
    "wav2vec2 = Wav2Vec2ForPreTraining.from_pretrained(model_name)\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ẻ': 0,\n",
       " '6': 1,\n",
       " 'ụ': 2,\n",
       " 'í': 3,\n",
       " '3': 4,\n",
       " 'ỹ': 5,\n",
       " 'ý': 6,\n",
       " 'ẩ': 7,\n",
       " 'ở': 8,\n",
       " 'ề': 9,\n",
       " 'õ': 10,\n",
       " '7': 11,\n",
       " 'ê': 12,\n",
       " 'ứ': 13,\n",
       " 'ỏ': 14,\n",
       " 'v': 15,\n",
       " 'ỷ': 16,\n",
       " 'a': 17,\n",
       " 'l': 18,\n",
       " 'ự': 19,\n",
       " 'q': 20,\n",
       " 'ờ': 21,\n",
       " 'j': 22,\n",
       " 'ố': 23,\n",
       " 'à': 24,\n",
       " 'ỗ': 25,\n",
       " 'n': 26,\n",
       " 'é': 27,\n",
       " 'ủ': 28,\n",
       " 'у': 29,\n",
       " 'ô': 30,\n",
       " 'u': 31,\n",
       " 'y': 32,\n",
       " 'ằ': 33,\n",
       " '4': 34,\n",
       " 'w': 35,\n",
       " 'b': 36,\n",
       " 'ệ': 37,\n",
       " 'ễ': 38,\n",
       " 's': 39,\n",
       " 'ì': 40,\n",
       " 'ầ': 41,\n",
       " 'ỵ': 42,\n",
       " '8': 43,\n",
       " 'd': 44,\n",
       " 'ể': 45,\n",
       " 'r': 47,\n",
       " 'ũ': 48,\n",
       " 'c': 49,\n",
       " 'ạ': 50,\n",
       " '9': 51,\n",
       " 'ế': 52,\n",
       " 'ù': 53,\n",
       " 'ỡ': 54,\n",
       " '2': 55,\n",
       " 't': 56,\n",
       " 'i': 57,\n",
       " 'g': 58,\n",
       " '́': 59,\n",
       " 'ử': 60,\n",
       " '̀': 61,\n",
       " 'á': 62,\n",
       " '0': 63,\n",
       " 'ậ': 64,\n",
       " 'e': 65,\n",
       " 'ộ': 66,\n",
       " 'm': 67,\n",
       " 'ẳ': 68,\n",
       " 'ợ': 69,\n",
       " 'ĩ': 70,\n",
       " 'h': 71,\n",
       " 'â': 72,\n",
       " 'ú': 73,\n",
       " 'ọ': 74,\n",
       " 'ồ': 75,\n",
       " 'ặ': 76,\n",
       " 'f': 77,\n",
       " 'ữ': 78,\n",
       " 'ắ': 79,\n",
       " 'ỳ': 80,\n",
       " 'x': 81,\n",
       " 'ó': 82,\n",
       " 'ã': 83,\n",
       " 'ổ': 84,\n",
       " 'ị': 85,\n",
       " '̣': 86,\n",
       " 'z': 87,\n",
       " 'ả': 88,\n",
       " 'đ': 89,\n",
       " 'è': 90,\n",
       " 'ừ': 91,\n",
       " 'ò': 92,\n",
       " 'ẵ': 93,\n",
       " '1': 94,\n",
       " 'ơ': 95,\n",
       " 'k': 96,\n",
       " 'ẫ': 97,\n",
       " 'p': 98,\n",
       " 'ấ': 99,\n",
       " 'ẽ': 100,\n",
       " 'ỉ': 101,\n",
       " 'ớ': 102,\n",
       " 'ẹ': 103,\n",
       " 'ă': 104,\n",
       " 'o': 105,\n",
       " 'ư': 106,\n",
       " '5': 107,\n",
       " '|': 46,\n",
       " '<unk>': 108,\n",
       " '<pad>': 109,\n",
       " '<s>': 110,\n",
       " '</s>': 111}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1362: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SpeechRecognizer(wav2vec2, tokenizer, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(CKPT_DIR, monitor=\"val/wer\", mode=\"min\", save_top_k=1)\n",
    "    ],\n",
    "    logger=TensorBoardLogger(LOG_DIR),\n",
    "    max_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs/lightning_logs\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | wav2vec2   | Wav2Vec2ForPreTraining | 95.0 M\n",
      "1 | dropout    | Dropout                | 0     \n",
      "2 | fc         | Sequential             | 337 K \n",
      "3 | criterion  | CTCLoss                | 0     \n",
      "4 | train_loss | MeanMetric             | 0     \n",
      "------------------------------------------------------\n",
      "91.2 M    Trainable params\n",
      "4.2 M     Non-trainable params\n",
      "95.4 M    Total params\n",
      "381.529   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e65e9bbe2b4e5c86fd0954e69f2779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"xin chào 😃\", \"cô gái nông thôn\"], return_tensors=\"pt\", padding=True, return_length=True).input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 81,  57,  26,  46,  49,  71,  24, 105,  46, 108, 109, 109, 109, 109,\n",
       "         109, 109],\n",
       "        [ 49,  30,  46,  58,  62,  57,  46,  26,  30,  26,  58,  46,  56,  71,\n",
       "          30,  26]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xin chào <unk>', 'cô gái nông thôn']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ẻ': 0,\n",
       " '6': 1,\n",
       " 'ụ': 2,\n",
       " 'í': 3,\n",
       " '3': 4,\n",
       " 'ỹ': 5,\n",
       " 'ý': 6,\n",
       " 'ẩ': 7,\n",
       " 'ở': 8,\n",
       " 'ề': 9,\n",
       " 'õ': 10,\n",
       " '7': 11,\n",
       " 'ê': 12,\n",
       " 'ứ': 13,\n",
       " 'ỏ': 14,\n",
       " 'v': 15,\n",
       " 'ỷ': 16,\n",
       " 'a': 17,\n",
       " 'l': 18,\n",
       " 'ự': 19,\n",
       " 'q': 20,\n",
       " 'ờ': 21,\n",
       " 'j': 22,\n",
       " 'ố': 23,\n",
       " 'à': 24,\n",
       " 'ỗ': 25,\n",
       " 'n': 26,\n",
       " 'é': 27,\n",
       " 'ủ': 28,\n",
       " 'у': 29,\n",
       " 'ô': 30,\n",
       " 'u': 31,\n",
       " 'y': 32,\n",
       " 'ằ': 33,\n",
       " '4': 34,\n",
       " 'w': 35,\n",
       " 'b': 36,\n",
       " 'ệ': 37,\n",
       " 'ễ': 38,\n",
       " 's': 39,\n",
       " 'ì': 40,\n",
       " 'ầ': 41,\n",
       " 'ỵ': 42,\n",
       " '8': 43,\n",
       " 'd': 44,\n",
       " 'ể': 45,\n",
       " 'r': 47,\n",
       " 'ũ': 48,\n",
       " 'c': 49,\n",
       " 'ạ': 50,\n",
       " '9': 51,\n",
       " 'ế': 52,\n",
       " 'ù': 53,\n",
       " 'ỡ': 54,\n",
       " '2': 55,\n",
       " 't': 56,\n",
       " 'i': 57,\n",
       " 'g': 58,\n",
       " '́': 59,\n",
       " 'ử': 60,\n",
       " '̀': 61,\n",
       " 'á': 62,\n",
       " '0': 63,\n",
       " 'ậ': 64,\n",
       " 'e': 65,\n",
       " 'ộ': 66,\n",
       " 'm': 67,\n",
       " 'ẳ': 68,\n",
       " 'ợ': 69,\n",
       " 'ĩ': 70,\n",
       " 'h': 71,\n",
       " 'â': 72,\n",
       " 'ú': 73,\n",
       " 'ọ': 74,\n",
       " 'ồ': 75,\n",
       " 'ặ': 76,\n",
       " 'f': 77,\n",
       " 'ữ': 78,\n",
       " 'ắ': 79,\n",
       " 'ỳ': 80,\n",
       " 'x': 81,\n",
       " 'ó': 82,\n",
       " 'ã': 83,\n",
       " 'ổ': 84,\n",
       " 'ị': 85,\n",
       " '̣': 86,\n",
       " 'z': 87,\n",
       " 'ả': 88,\n",
       " 'đ': 89,\n",
       " 'è': 90,\n",
       " 'ừ': 91,\n",
       " 'ò': 92,\n",
       " 'ẵ': 93,\n",
       " '1': 94,\n",
       " 'ơ': 95,\n",
       " 'k': 96,\n",
       " 'ẫ': 97,\n",
       " 'p': 98,\n",
       " 'ấ': 99,\n",
       " 'ẽ': 100,\n",
       " 'ỉ': 101,\n",
       " 'ớ': 102,\n",
       " 'ẹ': 103,\n",
       " 'ă': 104,\n",
       " 'o': 105,\n",
       " 'ư': 106,\n",
       " '5': 107,\n",
       " '|': 46,\n",
       " '<unk>': 108,\n",
       " '<pad>': 109,\n",
       " '<s>': 110,\n",
       " '</s>': 111}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.modules import Wav2Vec2Processor\n",
    "from src.model import Wav2Vec2PretrainingModule\n",
    "import torch\n",
    "\n",
    "\n",
    "def speech_to_text(waveforms: Tuple[torch.Tensor, ...]):\n",
    "\n",
    "    batched_waveforms, wavelengths = Wav2Vec2Processor()(waveforms)\n",
    "    attention_masks = Wav2Vec2PretrainingModule._compute_attention_mask(wavelengths)\n",
    "\n",
    "    logits = model(batched_waveforms, attention_mask=attention_masks).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    return processor.batch_decode(predicted_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character error rate: 25.47%\n",
      "Word error rate: 32.33%\n"
     ]
    }
   ],
   "source": [
    "cer, wer = 0, 0\n",
    "n_items = 0\n",
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    transcripts, waveforms = batch\n",
    "    predicted_transcripts = speech_to_text(waveforms)\n",
    "\n",
    "    for predicted_transcript, transcript in zip(predicted_transcripts, transcripts):\n",
    "        cer += character_error_rate(predicted_transcript, transcript)\n",
    "        wer += word_error_rate(predicted_transcript, transcript)\n",
    "\n",
    "        n_items += 1\n",
    "\n",
    "    if batch_idx > 100:\n",
    "        break\n",
    "\n",
    "    del transcript\n",
    "    del waveforms\n",
    "    del predicted_transcript\n",
    "    del batch\n",
    "\n",
    "cer /= n_items\n",
    "wer /= n_items\n",
    "\n",
    "print(f\"Character error rate: {cer:.2%}\")\n",
    "print(f\"Word error rate: {wer:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>predicted_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trước khi bắt đầu khởi hành hiển dự định đạp xe vào bốn giờ ba mươi phút sáng hàng ngày</td>\n",
       "      <td>trước khi bắt đầu khởi hành hiện dự định đạp xe và bốn giờ ba mươi phút sáng hằng ngày</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unk&gt; ngon</td>\n",
       "      <td>ớnđyvn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xin được cảm ơn những chia sẻ đầy cảm xúc của các khách mời đã giúp cho chúng tôi những người thuộc nhiều thế hệ được lớn lên trong hòa bình thêm trân trọng những mất mát hi sinh của thế hệ đi trước để có được một việt nam hòa bình giúp cho chúng tôi</td>\n",
       "      <td>xin được cảm ơn những chia sẻ đầy cảm xúc của các khách mời đã giúp cho chúng tôi những người thuộc nhiều thế hệ được lớn lên trong hòa bình thêm trân trọng những mất mát hi sinh của thấy đi trước để có được một việt nam hòa bình giúp cho chúng tôi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nguyễn trang đem thi thể chúa trịnh nộp cho quân tây sơn</td>\n",
       "      <td>nguyễn trang đem thi thể chúa trịnh nộp cho quân tây sơn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theo đó chủ mưu trong vụ án là bị cáo nguyễn minh hùng bị tuyên mười bảy năm tù với vai trò chỉ</td>\n",
       "      <td>theo đó chủ mưu trong vụ án là bị cáo nguyễn minh hùng bị tuyên mười bảy năm tù với vai trò chỉ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bây giờ sẽ là phần thi cuối cùng và cũng là &lt;unk&gt;</td>\n",
       "      <td>bây giờ sẽ là phần thi cuối cùng và cũn là</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>đồng thời lại nghe theo kiến nghị của quân sư ông cho đúc trở lại tiền ngũ thù khôi phục lưu thông tiền tệ trong địa bàn đem đến tiện lợi cho sinh hoạt của nhân dân không còn phải dùng xếp vải làm phương tiện thanh toán</td>\n",
       "      <td>đồng thời lại nghe theo kýn nghị của quân sư ông cho đúc trở lại tiền ngủ thù khôi phục lưu thông tiền tệ trong địa bàn đem đến tiền lợi cho sinh hoạt của nhân dân không còn phải dùng xếp vãi làm phương tiện thanh toán</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chính quyền của tổng thống trăm nhằm cắt giảm các chương trình trợ cấp an sinh xã hội</td>\n",
       "      <td>chính quyền của tổng thống trămp nhắm cắt giảm các chương trình trơa cấp an sinh xã hộicc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>văn học việt nam là sự tích hợp từ hai dòng văn học dân gian và văn học viết của những người dùng tiếng việt</td>\n",
       "      <td>văn học việt nam là sự tích hợp từ hai dòng văn học dân gian và văn học viết của những người dùng tiếng việt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ui tình</td>\n",
       "      <td>ừừừ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dân trí sẽ tiếp tục cập nhật diễn biến của buổi họp báo này</td>\n",
       "      <td>dân chí sẽ tiếp tục cập nhật diễn biến của buổi họp báo nàys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>và đặc biệt là các bạn sẽ không thích các cuộc tán gẫu vặt tại vì bạn cảm thấy mệt mỏi khi phải duy trì một cuộc nói chuyện thực ra người hướng nội cũng có nhiều tuýp hướng nội khác nhau nhá</td>\n",
       "      <td>nhóm và đặc biệt là các bạn sại không thích những cuộc tán gỗ vặt tại vì bạn cảm thấy mệt mỏi khi phải duy trì một  cuộc nói chuyện thực ra người hướng nội cũng có nhiều cái tuýp hướng nội khác nhau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                    transcript  \\\n",
       "0                                                                                                                                                                      trước khi bắt đầu khởi hành hiển dự định đạp xe vào bốn giờ ba mươi phút sáng hàng ngày   \n",
       "1                                                                                                                                                                                                                                                   <unk> ngon   \n",
       "2   xin được cảm ơn những chia sẻ đầy cảm xúc của các khách mời đã giúp cho chúng tôi những người thuộc nhiều thế hệ được lớn lên trong hòa bình thêm trân trọng những mất mát hi sinh của thế hệ đi trước để có được một việt nam hòa bình giúp cho chúng tôi   \n",
       "3                                                                                                                                                                                                     nguyễn trang đem thi thể chúa trịnh nộp cho quân tây sơn   \n",
       "4                                                                                                                                                              theo đó chủ mưu trong vụ án là bị cáo nguyễn minh hùng bị tuyên mười bảy năm tù với vai trò chỉ   \n",
       "5                                                                                                                                                                                                            bây giờ sẽ là phần thi cuối cùng và cũng là <unk>   \n",
       "6                                  đồng thời lại nghe theo kiến nghị của quân sư ông cho đúc trở lại tiền ngũ thù khôi phục lưu thông tiền tệ trong địa bàn đem đến tiện lợi cho sinh hoạt của nhân dân không còn phải dùng xếp vải làm phương tiện thanh toán   \n",
       "7                                                                                                                                                                        chính quyền của tổng thống trăm nhằm cắt giảm các chương trình trợ cấp an sinh xã hội   \n",
       "8                                                                                                                                                 văn học việt nam là sự tích hợp từ hai dòng văn học dân gian và văn học viết của những người dùng tiếng việt   \n",
       "9                                                                                                                                                                                                                                                      ui tình   \n",
       "10                                                                                                                                                                                                 dân trí sẽ tiếp tục cập nhật diễn biến của buổi họp báo này   \n",
       "11                                                              và đặc biệt là các bạn sẽ không thích các cuộc tán gẫu vặt tại vì bạn cảm thấy mệt mỏi khi phải duy trì một cuộc nói chuyện thực ra người hướng nội cũng có nhiều tuýp hướng nội khác nhau nhá   \n",
       "\n",
       "                                                                                                                                                                                                                                        predicted_transcript  \n",
       "0                                                                                                                                                                     trước khi bắt đầu khởi hành hiện dự định đạp xe và bốn giờ ba mươi phút sáng hằng ngày  \n",
       "1                                                                                                                                                                                                                                                     ớnđyvn  \n",
       "2   xin được cảm ơn những chia sẻ đầy cảm xúc của các khách mời đã giúp cho chúng tôi những người thuộc nhiều thế hệ được lớn lên trong hòa bình thêm trân trọng những mất mát hi sinh của thấy đi trước để có được một việt nam hòa bình giúp cho chúng tôi  \n",
       "3                                                                                                                                                                                                   nguyễn trang đem thi thể chúa trịnh nộp cho quân tây sơn  \n",
       "4                                                                                                                                                            theo đó chủ mưu trong vụ án là bị cáo nguyễn minh hùng bị tuyên mười bảy năm tù với vai trò chỉ  \n",
       "5                                                                                                                                                                                                                 bây giờ sẽ là phần thi cuối cùng và cũn là  \n",
       "6                                 đồng thời lại nghe theo kýn nghị của quân sư ông cho đúc trở lại tiền ngủ thù khôi phục lưu thông tiền tệ trong địa bàn đem đến tiền lợi cho sinh hoạt của nhân dân không còn phải dùng xếp vãi làm phương tiện thanh toán  \n",
       "7                                                                                                                                                                  chính quyền của tổng thống trămp nhắm cắt giảm các chương trình trơa cấp an sinh xã hộicc  \n",
       "8                                                                                                                                               văn học việt nam là sự tích hợp từ hai dòng văn học dân gian và văn học viết của những người dùng tiếng việt  \n",
       "9                                                                                                                                                                                                                                                        ừừừ  \n",
       "10                                                                                                                                                                                              dân chí sẽ tiếp tục cập nhật diễn biến của buổi họp báo nàys  \n",
       "11                                                    nhóm và đặc biệt là các bạn sại không thích những cuộc tán gỗ vặt tại vì bạn cảm thấy mệt mỏi khi phải duy trì một  cuộc nói chuyện thực ra người hướng nội cũng có nhiều cái tuýp hướng nội khác nhau  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = []\n",
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    if batch_idx > 5:\n",
    "        break\n",
    "\n",
    "    transcripts, waveforms = batch\n",
    "    predicted_transcripts = speech_to_text(waveforms)\n",
    "\n",
    "    for predicted_transcript, transcript in zip(predicted_transcripts, transcripts):\n",
    "        m.append(\n",
    "            {\n",
    "                \"transcript\": transcript,\n",
    "                \"predicted_transcript\": predicted_transcript,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.DataFrame.from_dict(m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
