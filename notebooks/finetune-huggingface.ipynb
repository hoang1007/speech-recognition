{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from typing import Tuple, Iterable, Optional\n",
    "import re\n",
    "import torch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define The Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "FINETUNE_LR = 1e-5\n",
    "LR = 1e-4\n",
    "EPOCHS = 30\n",
    "TOTAL_STEPS = (42_000 // BATCH_SIZE) * EPOCHS\n",
    "WARMUP_STEPS = int(TOTAL_STEPS * 0.1)\n",
    "CONSTANT_STEPS = int(TOTAL_STEPS * 0.4)\n",
    "WEIGHT_DECAY = 5e-3\n",
    "\n",
    "CKPT_DIR = \"ckpt\"\n",
    "LOG_DIR = \"logs\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert original dataset to WebDataset tar file for faster loading on Google Colab\n",
    "from src.datamodule import VLSP2020Dataset, VLSP2020TarDataset\n",
    "\n",
    "# from torch.utils.data import random_split\n",
    "\n",
    "# dts = VLSP2020Dataset(\"../data/vlsp2020_train_set_02\")\n",
    "# train_set, val_set = random_split(dts, [42_000, 14_427])\n",
    "\n",
    "# VLSP2020TarDataset(\"../data/vlsp2020_train_set.tar\").convert(train_set)\n",
    "# VLSP2020TarDataset(\"../data/vlsp2020_val_set.tar\").convert(val_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloader and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VLSP2020TarDataset(\"../data/vlsp2020_train_set.tar\").load()\n",
    "val_dataset = VLSP2020TarDataset(\"../data/vlsp2020_val_set.tar\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from src.datamodule.vlsp2020 import get_dataloader\n",
    "\n",
    "\n",
    "def remove_punctuation(text: str):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    train_dataset,\n",
    "    return_transcript=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_transform=remove_punctuation,\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    val_dataset,\n",
    "    return_transcript=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_transform=remove_punctuation,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('v√† h√¨nh nh∆∞ t√¥i c·∫£m gi√°c l√† qua t·ª´ng v√≤ng thi th√¨ c√°i h·ªçng c·ªßa b·∫°n t·ªët h∆°n r·ªìi th√¨ ph·∫£i', 'ƒë·∫øn ƒë√¢y th√¨ m·ªçi b·∫Øt ƒë·∫ßu th·∫•y ƒë∆∞·ª£c cu·ªôc chi·∫øn kh·ªëc li·ªát nh∆∞ th·∫ø n√†o r·ªìi ƒë√∫ng kh√¥ng ·∫° h·ªç r·∫•t l√† t√≠nh tay r·∫•t kƒ© th∆∞a qu√Ω v·ªã ch·ªçn √¥ m√†u c·ªßa m√¨nh m·ªùi em ƒë·ªçc c√¢u ti·∫øp theo'), (tensor([-0.0012,  0.0088,  0.0054,  ..., -0.0038, -0.0009,  0.0046]), tensor([-0.0760, -0.0811, -0.0728,  ..., -0.0032, -0.0034, -0.0035])))\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(source: Tuple[str], target: Tuple[str]):\n",
    "    \"\"\"\n",
    "    Compute the Levenshtein distance between two sequences.\n",
    "    \"\"\"\n",
    "\n",
    "    n, m = len(source), len(target)\n",
    "    if n > m:\n",
    "        # Make sure n <= m, to use O(min(n,m)) space\n",
    "        source, target = target, source\n",
    "        n, m = m, n\n",
    "\n",
    "    current_row = range(n + 1)  # Keep current and previous row, not entire matrix\n",
    "    for i in range(1, m + 1):\n",
    "        previous_row, current_row = current_row, [i] + [0] * n\n",
    "        for j in range(1, n + 1):\n",
    "            add, delete, change = (\n",
    "                previous_row[j] + 1,\n",
    "                current_row[j - 1] + 1,\n",
    "                previous_row[j - 1],\n",
    "            )\n",
    "            if source[j - 1] != target[i - 1]:\n",
    "                change += 1\n",
    "            current_row[j] = min(add, delete, change)\n",
    "\n",
    "    distance = current_row[n]\n",
    "\n",
    "    del current_row\n",
    "    del previous_row\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def word_error_rate(prediction: str, transcript: str):\n",
    "    pattern = r\"\\W+\"\n",
    "\n",
    "    prediction = re.split(pattern, prediction)\n",
    "    transcript = re.split(pattern, transcript)\n",
    "\n",
    "    return levenshtein_distance(prediction, transcript) / len(transcript)\n",
    "\n",
    "\n",
    "def character_error_rate(prediction: str, transcript: str):\n",
    "    return levenshtein_distance(prediction, transcript) / len(transcript)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class VocabBuilder:\n",
    "    DELIM_TOKEN = \"|\"\n",
    "    UNK_TOKEN = \"<unk>\"\n",
    "    PAD_TOKEN = \"<pad>\"\n",
    "\n",
    "    def __init__(self, vocab_file: str):\n",
    "        self.vocab_file = vocab_file\n",
    "        self._vocab_set = set()\n",
    "\n",
    "    def add(self, texts: Iterable[str]):\n",
    "        for t in texts:\n",
    "            self._vocab_set.update(t)\n",
    "\n",
    "    def build(self):\n",
    "        self._vocab_dict = {c: i for i, c in enumerate(self._vocab_set)}\n",
    "\n",
    "        # replace space with pipe for clearer visualization\n",
    "        self._vocab_dict[self.DELIM_TOKEN] = self._vocab_dict[\" \"]\n",
    "        del self._vocab_dict[\" \"]\n",
    "\n",
    "        # add unknown token so that model can handle unseen characters\n",
    "        self._vocab_dict[self.UNK_TOKEN] = len(self._vocab_dict)\n",
    "\n",
    "        # add padding token for CTC\n",
    "        self._vocab_dict[self.PAD_TOKEN] = len(self._vocab_dict)\n",
    "\n",
    "        return self._vocab_dict\n",
    "\n",
    "    @property\n",
    "    def vocab_dict(self):\n",
    "        return self._vocab_dict\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.vocab_file, \"w\") as f:\n",
    "            json.dump(self.vocab_dict, f, ensure_ascii=False)\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.vocab_file, \"r\") as f:\n",
    "            self._vocab_dict = json.load(f)\n",
    "\n",
    "        return self._vocab_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from transformers import (\n",
    "    Wav2Vec2ForPreTraining,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    ")\n",
    "from torchmetrics import MeanMetric\n",
    "\n",
    "from src.utils.scheduler import TriStateScheduler\n",
    "\n",
    "class SpeechRecognizer(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        wav2vec2: Wav2Vec2ForPreTraining,\n",
    "        tokenizer: Wav2Vec2CTCTokenizer,\n",
    "        feature_extractor: Wav2Vec2FeatureExtractor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.hidden_size = wav2vec2.config.hidden_size\n",
    "        self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "        self.wav2vec2 = wav2vec2\n",
    "        self.wav2vec2.freeze_feature_extractor()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(self.hidden_size // 2, self.vocab_size),\n",
    "        )\n",
    "\n",
    "        self.criterion = torch.nn.CTCLoss(blank=tokenizer.pad_token_id)\n",
    "\n",
    "        self.train_loss = MeanMetric()\n",
    "\n",
    "    def forward(self, waveforms: Tuple[torch.Tensor], transcripts: Tuple[str] = None):\n",
    "        # convert torch.Tensor to numpy.ndarray\n",
    "        waveforms = tuple(waveform.cpu().numpy() for waveform in waveforms)\n",
    "\n",
    "        extracted = self.feature_extractor(\n",
    "            waveforms,\n",
    "            sampling_rate=16000,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "\n",
    "        outputs = self.wav2vec2(\n",
    "            extracted.input_values,\n",
    "            attention_mask=extracted.attention_mask,\n",
    "        )\n",
    "\n",
    "        # hidden_states.shape == (batch_size, sequence_length, hidden_size)\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # logits.shape == (batch_size, sequence_length, vocab_size)\n",
    "        logits = self.fc(hidden_states)\n",
    "\n",
    "        if transcripts is not None:\n",
    "            # get the length of valids sequence\n",
    "            input_lengths = self.wav2vec2._get_feat_extract_output_lengths(\n",
    "                extracted.attention_mask.sum(-1)\n",
    "            ).to(torch.long)\n",
    "\n",
    "            # tokenize transcripts\n",
    "            target_ids, target_lengths = self.tokenizer(\n",
    "                transcripts, padding=True, return_length=True, return_tensors=\"pt\"\n",
    "            ).values()\n",
    "\n",
    "            # (batch_size, sequence_length, vocab_size) -> (sequence_length, batch_size, vocab_size)\n",
    "            log_probs = torch.nn.functional.log_softmax(logits, dim=-1).transpose_(0, 1)\n",
    "\n",
    "            # compute loss\n",
    "            loss = self.criterion(log_probs, target_ids, input_lengths, target_lengths)\n",
    "\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        transcripts, waveforms = batch\n",
    "\n",
    "        loss, logits = self(waveforms, transcripts)\n",
    "\n",
    "        self.train_loss(loss)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            self.log(\"train/loss\", self.train_loss, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self.train_loss.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        transcripts, waveforms = batch\n",
    "\n",
    "        logits = self(waveforms)\n",
    "\n",
    "        predicted_ids = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "\n",
    "        predicted_texts = self.tokenizer.batch_decode(predicted_ids)\n",
    "\n",
    "        wer = word_error_rate(predicted_texts, transcripts)\n",
    "        cer = character_error_rate(predicted_texts, transcripts)\n",
    "\n",
    "        self.log(\"val/wer\", wer, on_epoch=True)\n",
    "        self.log(\"val/cer\", cer, on_epoch=True)\n",
    "\n",
    "        return wer, cer\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\"params\": self.wav2vec2.parameters(), \"lr\": FINETUNE_LR},\n",
    "            {\"params\": self.fc.parameters(), \"lr\": LR},\n",
    "        ], lr=LR, weight_decay=WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        scheduler = TriStateScheduler(\n",
    "            optimizer,\n",
    "            total_steps=TOTAL_STEPS,\n",
    "            warmup_steps=WARMUP_STEPS,\n",
    "            constant_steps=CONSTANT_STEPS,\n",
    "            factor=1e-3\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h were not used when initializing Wav2Vec2ForPreTraining: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForPreTraining were not initialized from the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h and are newly initialized: ['project_q.bias', 'quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_hid.bias', 'project_hid.weight', 'project_q.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nguyenvulebinh/wav2vec2-base-vietnamese-250h\"\n",
    "\n",
    "wav2vec2 = Wav2Vec2ForPreTraining.from_pretrained(model_name)\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(model_name)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'·∫ª': 0,\n",
       " '6': 1,\n",
       " '·ª•': 2,\n",
       " '√≠': 3,\n",
       " '3': 4,\n",
       " '·ªπ': 5,\n",
       " '√Ω': 6,\n",
       " '·∫©': 7,\n",
       " '·ªü': 8,\n",
       " '·ªÅ': 9,\n",
       " '√µ': 10,\n",
       " '7': 11,\n",
       " '√™': 12,\n",
       " '·ª©': 13,\n",
       " '·ªè': 14,\n",
       " 'v': 15,\n",
       " '·ª∑': 16,\n",
       " 'a': 17,\n",
       " 'l': 18,\n",
       " '·ª±': 19,\n",
       " 'q': 20,\n",
       " '·ªù': 21,\n",
       " 'j': 22,\n",
       " '·ªë': 23,\n",
       " '√†': 24,\n",
       " '·ªó': 25,\n",
       " 'n': 26,\n",
       " '√©': 27,\n",
       " '·ªß': 28,\n",
       " '—É': 29,\n",
       " '√¥': 30,\n",
       " 'u': 31,\n",
       " 'y': 32,\n",
       " '·∫±': 33,\n",
       " '4': 34,\n",
       " 'w': 35,\n",
       " 'b': 36,\n",
       " '·ªá': 37,\n",
       " '·ªÖ': 38,\n",
       " 's': 39,\n",
       " '√¨': 40,\n",
       " '·∫ß': 41,\n",
       " '·ªµ': 42,\n",
       " '8': 43,\n",
       " 'd': 44,\n",
       " '·ªÉ': 45,\n",
       " 'r': 47,\n",
       " '≈©': 48,\n",
       " 'c': 49,\n",
       " '·∫°': 50,\n",
       " '9': 51,\n",
       " '·∫ø': 52,\n",
       " '√π': 53,\n",
       " '·ª°': 54,\n",
       " '2': 55,\n",
       " 't': 56,\n",
       " 'i': 57,\n",
       " 'g': 58,\n",
       " 'ÃÅ': 59,\n",
       " '·ª≠': 60,\n",
       " 'ÃÄ': 61,\n",
       " '√°': 62,\n",
       " '0': 63,\n",
       " '·∫≠': 64,\n",
       " 'e': 65,\n",
       " '·ªô': 66,\n",
       " 'm': 67,\n",
       " '·∫≥': 68,\n",
       " '·ª£': 69,\n",
       " 'ƒ©': 70,\n",
       " 'h': 71,\n",
       " '√¢': 72,\n",
       " '√∫': 73,\n",
       " '·ªç': 74,\n",
       " '·ªì': 75,\n",
       " '·∫∑': 76,\n",
       " 'f': 77,\n",
       " '·ªØ': 78,\n",
       " '·∫Ø': 79,\n",
       " '·ª≥': 80,\n",
       " 'x': 81,\n",
       " '√≥': 82,\n",
       " '√£': 83,\n",
       " '·ªï': 84,\n",
       " '·ªã': 85,\n",
       " 'Ã£': 86,\n",
       " 'z': 87,\n",
       " '·∫£': 88,\n",
       " 'ƒë': 89,\n",
       " '√®': 90,\n",
       " '·ª´': 91,\n",
       " '√≤': 92,\n",
       " '·∫µ': 93,\n",
       " '1': 94,\n",
       " '∆°': 95,\n",
       " 'k': 96,\n",
       " '·∫´': 97,\n",
       " 'p': 98,\n",
       " '·∫•': 99,\n",
       " '·∫Ω': 100,\n",
       " '·ªâ': 101,\n",
       " '·ªõ': 102,\n",
       " '·∫π': 103,\n",
       " 'ƒÉ': 104,\n",
       " 'o': 105,\n",
       " '∆∞': 106,\n",
       " '5': 107,\n",
       " '|': 46,\n",
       " '<unk>': 108,\n",
       " '<pad>': 109,\n",
       " '<s>': 110,\n",
       " '</s>': 111}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1362: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SpeechRecognizer(wav2vec2, tokenizer, feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.16.0-unknown is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 0.1.43ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1.1build1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/hoang/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:175: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(CKPT_DIR, monitor=\"val/wer\", mode=\"min\", save_top_k=1)\n",
    "    ],\n",
    "    logger=TensorBoardLogger(LOG_DIR),\n",
    "    max_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs/lightning_logs\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | wav2vec2   | Wav2Vec2ForPreTraining | 95.0 M\n",
      "1 | dropout    | Dropout                | 0     \n",
      "2 | fc         | Sequential             | 337 K \n",
      "3 | criterion  | CTCLoss                | 0     \n",
      "4 | train_loss | MeanMetric             | 0     \n",
      "------------------------------------------------------\n",
      "91.2 M    Trainable params\n",
      "4.2 M     Non-trainable params\n",
      "95.4 M    Total params\n",
      "381.529   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e65e9bbe2b4e5c86fd0954e69f2779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"xin ch√†o üòÉ\", \"c√¥ g√°i n√¥ng th√¥n\"], return_tensors=\"pt\", padding=True, return_length=True).input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 81,  57,  26,  46,  49,  71,  24, 105,  46, 108, 109, 109, 109, 109,\n",
       "         109, 109],\n",
       "        [ 49,  30,  46,  58,  62,  57,  46,  26,  30,  26,  58,  46,  56,  71,\n",
       "          30,  26]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xin ch√†o <unk>', 'c√¥ g√°i n√¥ng th√¥n']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'·∫ª': 0,\n",
       " '6': 1,\n",
       " '·ª•': 2,\n",
       " '√≠': 3,\n",
       " '3': 4,\n",
       " '·ªπ': 5,\n",
       " '√Ω': 6,\n",
       " '·∫©': 7,\n",
       " '·ªü': 8,\n",
       " '·ªÅ': 9,\n",
       " '√µ': 10,\n",
       " '7': 11,\n",
       " '√™': 12,\n",
       " '·ª©': 13,\n",
       " '·ªè': 14,\n",
       " 'v': 15,\n",
       " '·ª∑': 16,\n",
       " 'a': 17,\n",
       " 'l': 18,\n",
       " '·ª±': 19,\n",
       " 'q': 20,\n",
       " '·ªù': 21,\n",
       " 'j': 22,\n",
       " '·ªë': 23,\n",
       " '√†': 24,\n",
       " '·ªó': 25,\n",
       " 'n': 26,\n",
       " '√©': 27,\n",
       " '·ªß': 28,\n",
       " '—É': 29,\n",
       " '√¥': 30,\n",
       " 'u': 31,\n",
       " 'y': 32,\n",
       " '·∫±': 33,\n",
       " '4': 34,\n",
       " 'w': 35,\n",
       " 'b': 36,\n",
       " '·ªá': 37,\n",
       " '·ªÖ': 38,\n",
       " 's': 39,\n",
       " '√¨': 40,\n",
       " '·∫ß': 41,\n",
       " '·ªµ': 42,\n",
       " '8': 43,\n",
       " 'd': 44,\n",
       " '·ªÉ': 45,\n",
       " 'r': 47,\n",
       " '≈©': 48,\n",
       " 'c': 49,\n",
       " '·∫°': 50,\n",
       " '9': 51,\n",
       " '·∫ø': 52,\n",
       " '√π': 53,\n",
       " '·ª°': 54,\n",
       " '2': 55,\n",
       " 't': 56,\n",
       " 'i': 57,\n",
       " 'g': 58,\n",
       " 'ÃÅ': 59,\n",
       " '·ª≠': 60,\n",
       " 'ÃÄ': 61,\n",
       " '√°': 62,\n",
       " '0': 63,\n",
       " '·∫≠': 64,\n",
       " 'e': 65,\n",
       " '·ªô': 66,\n",
       " 'm': 67,\n",
       " '·∫≥': 68,\n",
       " '·ª£': 69,\n",
       " 'ƒ©': 70,\n",
       " 'h': 71,\n",
       " '√¢': 72,\n",
       " '√∫': 73,\n",
       " '·ªç': 74,\n",
       " '·ªì': 75,\n",
       " '·∫∑': 76,\n",
       " 'f': 77,\n",
       " '·ªØ': 78,\n",
       " '·∫Ø': 79,\n",
       " '·ª≥': 80,\n",
       " 'x': 81,\n",
       " '√≥': 82,\n",
       " '√£': 83,\n",
       " '·ªï': 84,\n",
       " '·ªã': 85,\n",
       " 'Ã£': 86,\n",
       " 'z': 87,\n",
       " '·∫£': 88,\n",
       " 'ƒë': 89,\n",
       " '√®': 90,\n",
       " '·ª´': 91,\n",
       " '√≤': 92,\n",
       " '·∫µ': 93,\n",
       " '1': 94,\n",
       " '∆°': 95,\n",
       " 'k': 96,\n",
       " '·∫´': 97,\n",
       " 'p': 98,\n",
       " '·∫•': 99,\n",
       " '·∫Ω': 100,\n",
       " '·ªâ': 101,\n",
       " '·ªõ': 102,\n",
       " '·∫π': 103,\n",
       " 'ƒÉ': 104,\n",
       " 'o': 105,\n",
       " '∆∞': 106,\n",
       " '5': 107,\n",
       " '|': 46,\n",
       " '<unk>': 108,\n",
       " '<pad>': 109,\n",
       " '<s>': 110,\n",
       " '</s>': 111}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.modules import Wav2Vec2Processor\n",
    "from src.model import Wav2Vec2PretrainingModule\n",
    "import torch\n",
    "\n",
    "\n",
    "def speech_to_text(waveforms: Tuple[torch.Tensor, ...]):\n",
    "\n",
    "    batched_waveforms, wavelengths = Wav2Vec2Processor()(waveforms)\n",
    "    attention_masks = Wav2Vec2PretrainingModule._compute_attention_mask(wavelengths)\n",
    "\n",
    "    logits = model(batched_waveforms, attention_mask=attention_masks).logits\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    return processor.batch_decode(predicted_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character error rate: 25.47%\n",
      "Word error rate: 32.33%\n"
     ]
    }
   ],
   "source": [
    "cer, wer = 0, 0\n",
    "n_items = 0\n",
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    transcripts, waveforms = batch\n",
    "    predicted_transcripts = speech_to_text(waveforms)\n",
    "\n",
    "    for predicted_transcript, transcript in zip(predicted_transcripts, transcripts):\n",
    "        cer += character_error_rate(predicted_transcript, transcript)\n",
    "        wer += word_error_rate(predicted_transcript, transcript)\n",
    "\n",
    "        n_items += 1\n",
    "\n",
    "    if batch_idx > 100:\n",
    "        break\n",
    "\n",
    "    del transcript\n",
    "    del waveforms\n",
    "    del predicted_transcript\n",
    "    del batch\n",
    "\n",
    "cer /= n_items\n",
    "wer /= n_items\n",
    "\n",
    "print(f\"Character error rate: {cer:.2%}\")\n",
    "print(f\"Word error rate: {wer:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>predicted_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu kh·ªüi h√†nh hi·ªÉn d·ª± ƒë·ªãnh ƒë·∫°p xe v√†o b·ªën gi·ªù ba m∆∞∆°i ph√∫t s√°ng h√†ng ng√†y</td>\n",
       "      <td>tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu kh·ªüi h√†nh hi·ªán d·ª± ƒë·ªãnh ƒë·∫°p xe v√† b·ªën gi·ªù ba m∆∞∆°i ph√∫t s√°ng h·∫±ng ng√†y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;unk&gt; ngon</td>\n",
       "      <td>·ªõnƒëyvn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xin ƒë∆∞·ª£c c·∫£m ∆°n nh·ªØng chia s·∫ª ƒë·∫ßy c·∫£m x√∫c c·ªßa c√°c kh√°ch m·ªùi ƒë√£ gi√∫p cho ch√∫ng t√¥i nh·ªØng ng∆∞·ªùi thu·ªôc nhi·ªÅu th·∫ø h·ªá ƒë∆∞·ª£c l·ªõn l√™n trong h√≤a b√¨nh th√™m tr√¢n tr·ªçng nh·ªØng m·∫•t m√°t hi sinh c·ªßa th·∫ø h·ªá ƒëi tr∆∞·ªõc ƒë·ªÉ c√≥ ƒë∆∞·ª£c m·ªôt vi·ªát nam h√≤a b√¨nh gi√∫p cho ch√∫ng t√¥i</td>\n",
       "      <td>xin ƒë∆∞·ª£c c·∫£m ∆°n nh·ªØng chia s·∫ª ƒë·∫ßy c·∫£m x√∫c c·ªßa c√°c kh√°ch m·ªùi ƒë√£ gi√∫p cho ch√∫ng t√¥i nh·ªØng ng∆∞·ªùi thu·ªôc nhi·ªÅu th·∫ø h·ªá ƒë∆∞·ª£c l·ªõn l√™n trong h√≤a b√¨nh th√™m tr√¢n tr·ªçng nh·ªØng m·∫•t m√°t hi sinh c·ªßa th·∫•y ƒëi tr∆∞·ªõc ƒë·ªÉ c√≥ ƒë∆∞·ª£c m·ªôt vi·ªát nam h√≤a b√¨nh gi√∫p cho ch√∫ng t√¥i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nguy·ªÖn trang ƒëem thi th·ªÉ ch√∫a tr·ªãnh n·ªôp cho qu√¢n t√¢y s∆°n</td>\n",
       "      <td>nguy·ªÖn trang ƒëem thi th·ªÉ ch√∫a tr·ªãnh n·ªôp cho qu√¢n t√¢y s∆°n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>theo ƒë√≥ ch·ªß m∆∞u trong v·ª• √°n l√† b·ªã c√°o nguy·ªÖn minh h√πng b·ªã tuy√™n m∆∞·ªùi b·∫£y nƒÉm t√π v·ªõi vai tr√≤ ch·ªâ</td>\n",
       "      <td>theo ƒë√≥ ch·ªß m∆∞u trong v·ª• √°n l√† b·ªã c√°o nguy·ªÖn minh h√πng b·ªã tuy√™n m∆∞·ªùi b·∫£y nƒÉm t√π v·ªõi vai tr√≤ ch·ªâ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b√¢y gi·ªù s·∫Ω l√† ph·∫ßn thi cu·ªëi c√πng v√† c≈©ng l√† &lt;unk&gt;</td>\n",
       "      <td>b√¢y gi·ªù s·∫Ω l√† ph·∫ßn thi cu·ªëi c√πng v√† c≈©n l√†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ƒë·ªìng th·ªùi l·∫°i nghe theo ki·∫øn ngh·ªã c·ªßa qu√¢n s∆∞ √¥ng cho ƒë√∫c tr·ªü l·∫°i ti·ªÅn ng≈© th√π kh√¥i ph·ª•c l∆∞u th√¥ng ti·ªÅn t·ªá trong ƒë·ªãa b√†n ƒëem ƒë·∫øn ti·ªán l·ª£i cho sinh ho·∫°t c·ªßa nh√¢n d√¢n kh√¥ng c√≤n ph·∫£i d√πng x·∫øp v·∫£i l√†m ph∆∞∆°ng ti·ªán thanh to√°n</td>\n",
       "      <td>ƒë·ªìng th·ªùi l·∫°i nghe theo k√Ωn ngh·ªã c·ªßa qu√¢n s∆∞ √¥ng cho ƒë√∫c tr·ªü l·∫°i ti·ªÅn ng·ªß th√π kh√¥i ph·ª•c l∆∞u th√¥ng ti·ªÅn t·ªá trong ƒë·ªãa b√†n ƒëem ƒë·∫øn ti·ªÅn l·ª£i cho sinh ho·∫°t c·ªßa nh√¢n d√¢n kh√¥ng c√≤n ph·∫£i d√πng x·∫øp v√£i l√†m ph∆∞∆°ng ti·ªán thanh to√°n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ch√≠nh quy·ªÅn c·ªßa t·ªïng th·ªëng trƒÉm nh·∫±m c·∫Øt gi·∫£m c√°c ch∆∞∆°ng tr√¨nh tr·ª£ c·∫•p an sinh x√£ h·ªôi</td>\n",
       "      <td>ch√≠nh quy·ªÅn c·ªßa t·ªïng th·ªëng trƒÉmp nh·∫Øm c·∫Øt gi·∫£m c√°c ch∆∞∆°ng tr√¨nh tr∆°a c·∫•p an sinh x√£ h·ªôicc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vƒÉn h·ªçc vi·ªát nam l√† s·ª± t√≠ch h·ª£p t·ª´ hai d√≤ng vƒÉn h·ªçc d√¢n gian v√† vƒÉn h·ªçc vi·∫øt c·ªßa nh·ªØng ng∆∞·ªùi d√πng ti·∫øng vi·ªát</td>\n",
       "      <td>vƒÉn h·ªçc vi·ªát nam l√† s·ª± t√≠ch h·ª£p t·ª´ hai d√≤ng vƒÉn h·ªçc d√¢n gian v√† vƒÉn h·ªçc vi·∫øt c·ªßa nh·ªØng ng∆∞·ªùi d√πng ti·∫øng vi·ªát</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ui t√¨nh</td>\n",
       "      <td>·ª´·ª´·ª´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d√¢n tr√≠ s·∫Ω ti·∫øp t·ª•c c·∫≠p nh·∫≠t di·ªÖn bi·∫øn c·ªßa bu·ªïi h·ªçp b√°o n√†y</td>\n",
       "      <td>d√¢n ch√≠ s·∫Ω ti·∫øp t·ª•c c·∫≠p nh·∫≠t di·ªÖn bi·∫øn c·ªßa bu·ªïi h·ªçp b√°o n√†ys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>v√† ƒë·∫∑c bi·ªát l√† c√°c b·∫°n s·∫Ω kh√¥ng th√≠ch c√°c cu·ªôc t√°n g·∫´u v·∫∑t t·∫°i v√¨ b·∫°n c·∫£m th·∫•y m·ªát m·ªèi khi ph·∫£i duy tr√¨ m·ªôt cu·ªôc n√≥i chuy·ªán th·ª±c ra ng∆∞·ªùi h∆∞·ªõng n·ªôi c≈©ng c√≥ nhi·ªÅu tu√Ωp h∆∞·ªõng n·ªôi kh√°c nhau nh√°</td>\n",
       "      <td>nh√≥m v√† ƒë·∫∑c bi·ªát l√† c√°c b·∫°n s·∫°i kh√¥ng th√≠ch nh·ªØng cu·ªôc t√°n g·ªó v·∫∑t t·∫°i v√¨ b·∫°n c·∫£m th·∫•y m·ªát m·ªèi khi ph·∫£i duy tr√¨ m·ªôt  cu·ªôc n√≥i chuy·ªán th·ª±c ra ng∆∞·ªùi h∆∞·ªõng n·ªôi c≈©ng c√≥ nhi·ªÅu c√°i tu√Ωp h∆∞·ªõng n·ªôi kh√°c nhau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                    transcript  \\\n",
       "0                                                                                                                                                                      tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu kh·ªüi h√†nh hi·ªÉn d·ª± ƒë·ªãnh ƒë·∫°p xe v√†o b·ªën gi·ªù ba m∆∞∆°i ph√∫t s√°ng h√†ng ng√†y   \n",
       "1                                                                                                                                                                                                                                                   <unk> ngon   \n",
       "2   xin ƒë∆∞·ª£c c·∫£m ∆°n nh·ªØng chia s·∫ª ƒë·∫ßy c·∫£m x√∫c c·ªßa c√°c kh√°ch m·ªùi ƒë√£ gi√∫p cho ch√∫ng t√¥i nh·ªØng ng∆∞·ªùi thu·ªôc nhi·ªÅu th·∫ø h·ªá ƒë∆∞·ª£c l·ªõn l√™n trong h√≤a b√¨nh th√™m tr√¢n tr·ªçng nh·ªØng m·∫•t m√°t hi sinh c·ªßa th·∫ø h·ªá ƒëi tr∆∞·ªõc ƒë·ªÉ c√≥ ƒë∆∞·ª£c m·ªôt vi·ªát nam h√≤a b√¨nh gi√∫p cho ch√∫ng t√¥i   \n",
       "3                                                                                                                                                                                                     nguy·ªÖn trang ƒëem thi th·ªÉ ch√∫a tr·ªãnh n·ªôp cho qu√¢n t√¢y s∆°n   \n",
       "4                                                                                                                                                              theo ƒë√≥ ch·ªß m∆∞u trong v·ª• √°n l√† b·ªã c√°o nguy·ªÖn minh h√πng b·ªã tuy√™n m∆∞·ªùi b·∫£y nƒÉm t√π v·ªõi vai tr√≤ ch·ªâ   \n",
       "5                                                                                                                                                                                                            b√¢y gi·ªù s·∫Ω l√† ph·∫ßn thi cu·ªëi c√πng v√† c≈©ng l√† <unk>   \n",
       "6                                  ƒë·ªìng th·ªùi l·∫°i nghe theo ki·∫øn ngh·ªã c·ªßa qu√¢n s∆∞ √¥ng cho ƒë√∫c tr·ªü l·∫°i ti·ªÅn ng≈© th√π kh√¥i ph·ª•c l∆∞u th√¥ng ti·ªÅn t·ªá trong ƒë·ªãa b√†n ƒëem ƒë·∫øn ti·ªán l·ª£i cho sinh ho·∫°t c·ªßa nh√¢n d√¢n kh√¥ng c√≤n ph·∫£i d√πng x·∫øp v·∫£i l√†m ph∆∞∆°ng ti·ªán thanh to√°n   \n",
       "7                                                                                                                                                                        ch√≠nh quy·ªÅn c·ªßa t·ªïng th·ªëng trƒÉm nh·∫±m c·∫Øt gi·∫£m c√°c ch∆∞∆°ng tr√¨nh tr·ª£ c·∫•p an sinh x√£ h·ªôi   \n",
       "8                                                                                                                                                 vƒÉn h·ªçc vi·ªát nam l√† s·ª± t√≠ch h·ª£p t·ª´ hai d√≤ng vƒÉn h·ªçc d√¢n gian v√† vƒÉn h·ªçc vi·∫øt c·ªßa nh·ªØng ng∆∞·ªùi d√πng ti·∫øng vi·ªát   \n",
       "9                                                                                                                                                                                                                                                      ui t√¨nh   \n",
       "10                                                                                                                                                                                                 d√¢n tr√≠ s·∫Ω ti·∫øp t·ª•c c·∫≠p nh·∫≠t di·ªÖn bi·∫øn c·ªßa bu·ªïi h·ªçp b√°o n√†y   \n",
       "11                                                              v√† ƒë·∫∑c bi·ªát l√† c√°c b·∫°n s·∫Ω kh√¥ng th√≠ch c√°c cu·ªôc t√°n g·∫´u v·∫∑t t·∫°i v√¨ b·∫°n c·∫£m th·∫•y m·ªát m·ªèi khi ph·∫£i duy tr√¨ m·ªôt cu·ªôc n√≥i chuy·ªán th·ª±c ra ng∆∞·ªùi h∆∞·ªõng n·ªôi c≈©ng c√≥ nhi·ªÅu tu√Ωp h∆∞·ªõng n·ªôi kh√°c nhau nh√°   \n",
       "\n",
       "                                                                                                                                                                                                                                        predicted_transcript  \n",
       "0                                                                                                                                                                     tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu kh·ªüi h√†nh hi·ªán d·ª± ƒë·ªãnh ƒë·∫°p xe v√† b·ªën gi·ªù ba m∆∞∆°i ph√∫t s√°ng h·∫±ng ng√†y  \n",
       "1                                                                                                                                                                                                                                                     ·ªõnƒëyvn  \n",
       "2   xin ƒë∆∞·ª£c c·∫£m ∆°n nh·ªØng chia s·∫ª ƒë·∫ßy c·∫£m x√∫c c·ªßa c√°c kh√°ch m·ªùi ƒë√£ gi√∫p cho ch√∫ng t√¥i nh·ªØng ng∆∞·ªùi thu·ªôc nhi·ªÅu th·∫ø h·ªá ƒë∆∞·ª£c l·ªõn l√™n trong h√≤a b√¨nh th√™m tr√¢n tr·ªçng nh·ªØng m·∫•t m√°t hi sinh c·ªßa th·∫•y ƒëi tr∆∞·ªõc ƒë·ªÉ c√≥ ƒë∆∞·ª£c m·ªôt vi·ªát nam h√≤a b√¨nh gi√∫p cho ch√∫ng t√¥i  \n",
       "3                                                                                                                                                                                                   nguy·ªÖn trang ƒëem thi th·ªÉ ch√∫a tr·ªãnh n·ªôp cho qu√¢n t√¢y s∆°n  \n",
       "4                                                                                                                                                            theo ƒë√≥ ch·ªß m∆∞u trong v·ª• √°n l√† b·ªã c√°o nguy·ªÖn minh h√πng b·ªã tuy√™n m∆∞·ªùi b·∫£y nƒÉm t√π v·ªõi vai tr√≤ ch·ªâ  \n",
       "5                                                                                                                                                                                                                 b√¢y gi·ªù s·∫Ω l√† ph·∫ßn thi cu·ªëi c√πng v√† c≈©n l√†  \n",
       "6                                 ƒë·ªìng th·ªùi l·∫°i nghe theo k√Ωn ngh·ªã c·ªßa qu√¢n s∆∞ √¥ng cho ƒë√∫c tr·ªü l·∫°i ti·ªÅn ng·ªß th√π kh√¥i ph·ª•c l∆∞u th√¥ng ti·ªÅn t·ªá trong ƒë·ªãa b√†n ƒëem ƒë·∫øn ti·ªÅn l·ª£i cho sinh ho·∫°t c·ªßa nh√¢n d√¢n kh√¥ng c√≤n ph·∫£i d√πng x·∫øp v√£i l√†m ph∆∞∆°ng ti·ªán thanh to√°n  \n",
       "7                                                                                                                                                                  ch√≠nh quy·ªÅn c·ªßa t·ªïng th·ªëng trƒÉmp nh·∫Øm c·∫Øt gi·∫£m c√°c ch∆∞∆°ng tr√¨nh tr∆°a c·∫•p an sinh x√£ h·ªôicc  \n",
       "8                                                                                                                                               vƒÉn h·ªçc vi·ªát nam l√† s·ª± t√≠ch h·ª£p t·ª´ hai d√≤ng vƒÉn h·ªçc d√¢n gian v√† vƒÉn h·ªçc vi·∫øt c·ªßa nh·ªØng ng∆∞·ªùi d√πng ti·∫øng vi·ªát  \n",
       "9                                                                                                                                                                                                                                                        ·ª´·ª´·ª´  \n",
       "10                                                                                                                                                                                              d√¢n ch√≠ s·∫Ω ti·∫øp t·ª•c c·∫≠p nh·∫≠t di·ªÖn bi·∫øn c·ªßa bu·ªïi h·ªçp b√°o n√†ys  \n",
       "11                                                    nh√≥m v√† ƒë·∫∑c bi·ªát l√† c√°c b·∫°n s·∫°i kh√¥ng th√≠ch nh·ªØng cu·ªôc t√°n g·ªó v·∫∑t t·∫°i v√¨ b·∫°n c·∫£m th·∫•y m·ªát m·ªèi khi ph·∫£i duy tr√¨ m·ªôt  cu·ªôc n√≥i chuy·ªán th·ª±c ra ng∆∞·ªùi h∆∞·ªõng n·ªôi c≈©ng c√≥ nhi·ªÅu c√°i tu√Ωp h∆∞·ªõng n·ªôi kh√°c nhau  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m = []\n",
    "\n",
    "for batch_idx, batch in enumerate(dataloader):\n",
    "    if batch_idx > 5:\n",
    "        break\n",
    "\n",
    "    transcripts, waveforms = batch\n",
    "    predicted_transcripts = speech_to_text(waveforms)\n",
    "\n",
    "    for predicted_transcript, transcript in zip(predicted_transcripts, transcripts):\n",
    "        m.append(\n",
    "            {\n",
    "                \"transcript\": transcript,\n",
    "                \"predicted_transcript\": predicted_transcript,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.DataFrame.from_dict(m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
